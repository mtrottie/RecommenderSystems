{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cdd7660-ff65-46d7-9de4-80cee43b29ce",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - SVD\n",
    "\n",
    "Collaborative recommendation systems employ both user-to-user and item-to-item approaches to generate personalized recommendations. These systems typically operate in two modes:\n",
    "- An offline mode for computing recommendations\n",
    "- An online mode for serving responses to customer queries\n",
    "\n",
    "When analyzing the computational complexity of these algorithms:\n",
    "- User-to-user comparisons: O(kn²), where n is the number of users and k represents the k-nearest neighbors\n",
    "- Item-to-item comparisons: Similarly O(kn²)\n",
    "- Space complexity: O(nk) for both approaches, as we need to store the top k closest matches for each user\n",
    "\n",
    "While the offline calculation of recommendations is computationally expensive, it can be distributed across multiple machines using various parallel processing techniques. However, working with sparse rating matrices presents additional challenges in computing similarities efficiently.\n",
    "\n",
    "To address these challenges, dimensionality reduction techniques can be employed to transform the rating matrices into a lower-dimensional space, resulting in a more compact representation. The two primary methods for this transformation are:\n",
    "\n",
    "1. Singular Value Decomposition (SVD)\n",
    "2. Principal Component Analysis (PCA)\n",
    "\n",
    "Let's explore these concepts through a practical example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa86598-81b3-4551-b9dc-ff1a6ebb1a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table prior to Pearson Correlation Coefficient calculation\n",
      "         movieA  movieB  movieC\n",
      "user-1      1.0     1.0     1.0\n",
      "user-2      7.0     7.0     7.0\n",
      "user-3      3.0     1.0     1.0\n",
      "user-4      5.0     7.0     7.0\n",
      "user-5      3.0     1.0     NaN\n",
      "user-6      5.0     7.0     NaN\n",
      "user-7      3.0     1.0     NaN\n",
      "user-8      5.0     7.0     NaN\n",
      "user-9      3.0     1.0     NaN\n",
      "user-10     5.0     7.0     NaN\n",
      "user-11     3.0     1.0     NaN\n",
      "user-12     5.0     7.0     NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# Ratings of users by products, 5 users 6 products\n",
    "data = {\n",
    "    'movieA': [1,7,3,5,3,5,3,5,3,5,3,5],\n",
    "    'movieB': [1,7,1,7,1,7,1,7,1,7,1,7],\n",
    "    'movieC': [1,7,1,7,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "}\n",
    "\n",
    "index = [f\"user-{i}\" for i in range(1, 13)];\n",
    "data_frame = pd.DataFrame(data, index=index).astype(float)\n",
    "\n",
    "print(\"Data table prior to Pearson Correlation Coefficient calculation\") \n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb58a7d-a696-45dc-8f36-e00e1740834d",
   "metadata": {},
   "source": [
    "In our dataset, we have a table showing users and their movie ratings. There's a notable gap in the data where users 5-12 haven't provided ratings for MovieC. Before we can proceed with dimensionality reduction, we need to handle these missing values.\n",
    "\n",
    "To address these missing ratings (NaN values), we have two options:\n",
    "1. Calculate the mean rating for each row (user's average rating)\n",
    "2. Calculate the mean rating for each column (movie's average rating)\n",
    "\n",
    "Given that MovieC has very few ratings (sparse column), we'll opt to use the row means - each user's average rating across other movies - to fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2421701-47e4-4e2f-9cf7-2cb94535660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row adjusted mean\n",
      "         movieA  movieB  movieC\n",
      "user-1      1.0     1.0     1.0\n",
      "user-2      7.0     7.0     7.0\n",
      "user-3      3.0     1.0     1.0\n",
      "user-4      5.0     7.0     7.0\n",
      "user-5      3.0     1.0     2.0\n",
      "user-6      5.0     7.0     6.0\n",
      "user-7      3.0     1.0     2.0\n",
      "user-8      5.0     7.0     6.0\n",
      "user-9      3.0     1.0     2.0\n",
      "user-10     5.0     7.0     6.0\n",
      "user-11     3.0     1.0     2.0\n",
      "user-12     5.0     7.0     6.0\n"
     ]
    }
   ],
   "source": [
    "data_frame = data_frame.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "print(\"Row adjusted mean\")\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc69a3a-950c-4357-92d7-9712a624ff10",
   "metadata": {},
   "source": [
    "You will need to use your imagination a bit, but imagine this list had a billion of users with hundreds of millions of movies. \n",
    "\n",
    "Singular Value Decomposition (SVD) is a fundamental matrix factorization technique in linear algebra and data analysis. It decomposes a matrix into three other matrices, revealing important properties of the original matrix. Some key points:\n",
    "\n",
    "1. Decomposition: For a matrix A, SVD factorizes it into A = USV^T, where:\n",
    "   - U is an orthogonal matrix of left singular vectors\n",
    "   - S is a diagonal matrix of singular values\n",
    "   - V^T is the transpose of an orthogonal matrix of right singular vectors\n",
    "2. Dimensionality Reduction: SVD can be used to create lower-rank approximations of the original matrix by keeping only the largest singular values and their corresponding singular vectors.\n",
    "3. Applications:\n",
    "   - Data compression\n",
    "   - Noise reduction in data\n",
    "   - Recommendation systems\n",
    "   - Latent semantic analysis in natural language processing\n",
    "4. Properties:\n",
    "   - Works on any real or complex matrix\n",
    "   - Reveals the rank of the matrix\n",
    "   - Useful for computing matrix inverses and pseudoinverses\n",
    "5. In machine learning: SVD helps in feature extraction and dimensionality reduction, making it easier to work with high-dimensional data.\n",
    "6. Computational aspects: There are efficient algorithms for computing SVD, making it practical for large datasets.\n",
    "\n",
    "Lets compute the similarity matrix using SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a486aa7-fbc0-4174-80b4-c527dda4e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      "           user-1    user-2    user-3    user-4    user-5    user-6    user-7  \\\n",
      "user-1   1.000000 -1.000000  0.886676 -0.886676  0.903327 -0.903327  0.903327   \n",
      "user-2  -1.000000  1.000000 -0.886676  0.886676 -0.903327  0.903327 -0.903327   \n",
      "user-3   0.886676 -0.886676  1.000000 -1.000000  0.999302 -0.999302  0.999302   \n",
      "user-4  -0.886676  0.886676 -1.000000  1.000000 -0.999302  0.999302 -0.999302   \n",
      "user-5   0.903327 -0.903327  0.999302 -0.999302  1.000000 -1.000000  1.000000   \n",
      "user-6  -0.903327  0.903327 -0.999302  0.999302 -1.000000  1.000000 -1.000000   \n",
      "user-7   0.903327 -0.903327  0.999302 -0.999302  1.000000 -1.000000  1.000000   \n",
      "user-8  -0.903327  0.903327 -0.999302  0.999302 -1.000000  1.000000 -1.000000   \n",
      "user-9   0.903327 -0.903327  0.999302 -0.999302  1.000000 -1.000000  1.000000   \n",
      "user-10 -0.903327  0.903327 -0.999302  0.999302 -1.000000  1.000000 -1.000000   \n",
      "user-11  0.903327 -0.903327  0.999302 -0.999302  1.000000 -1.000000  1.000000   \n",
      "user-12 -0.903327  0.903327 -0.999302  0.999302 -1.000000  1.000000 -1.000000   \n",
      "\n",
      "           user-8    user-9   user-10   user-11   user-12  \n",
      "user-1  -0.903327  0.903327 -0.903327  0.903327 -0.903327  \n",
      "user-2   0.903327 -0.903327  0.903327 -0.903327  0.903327  \n",
      "user-3  -0.999302  0.999302 -0.999302  0.999302 -0.999302  \n",
      "user-4   0.999302 -0.999302  0.999302 -0.999302  0.999302  \n",
      "user-5  -1.000000  1.000000 -1.000000  1.000000 -1.000000  \n",
      "user-6   1.000000 -1.000000  1.000000 -1.000000  1.000000  \n",
      "user-7  -1.000000  1.000000 -1.000000  1.000000 -1.000000  \n",
      "user-8   1.000000 -1.000000  1.000000 -1.000000  1.000000  \n",
      "user-9  -1.000000  1.000000 -1.000000  1.000000 -1.000000  \n",
      "user-10  1.000000 -1.000000  1.000000 -1.000000  1.000000  \n",
      "user-11 -1.000000  1.000000 -1.000000  1.000000 -1.000000  \n",
      "user-12  1.000000 -1.000000  1.000000 -1.000000  1.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# 1. First standardize the data (center and scale)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_frame)\n",
    "\n",
    "# 2. Perform SVD\n",
    "U, S, VT = np.linalg.svd(scaled_data, full_matrices=False)\n",
    "\n",
    "# 3. Create the similarity matrix\n",
    "# You can choose how many components to keep (k)\n",
    "k = 2  # for example, keeping 2 components\n",
    "\n",
    "# Reduce dimensions\n",
    "S_reduced = np.diag(S[:k])\n",
    "U_reduced = U[:, :k]\n",
    "VT_reduced = VT[:k, :]\n",
    "\n",
    "# Reconstruct the matrix with reduced dimensions\n",
    "reconstructed_matrix = U_reduced @ S_reduced @ VT_reduced\n",
    "\n",
    "# 4. Calculate similarity matrix (user-user similarities)\n",
    "similarity_matrix = np.zeros((len(data_frame), len(data_frame)))\n",
    "for i in range(len(data_frame)):\n",
    "    for j in range(len(data_frame)):\n",
    "        similarity_matrix[i][j] = 1 - cosine(reconstructed_matrix[i], reconstructed_matrix[j])\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix, \n",
    "    index=data_frame.index, \n",
    "    columns=data_frame.index\n",
    ")\n",
    "\n",
    "print(\"Similarity Matrix:\")\n",
    "print(similarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10546bdb-06d7-414b-9d7d-8d8eaaaaa47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
